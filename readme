# Introduction
Retaining high profitable customers is the number one business goal for many banks. Banking fraud, however, poses a significant threat to this goal for different banks. In terms of substantial financial losses, trust, and credibility, this is a concerning issue for both banks and customers alike.
It has been estimated by Nilson Report that by 2020, banking frauds would account for $30 billion worldwide. With the rise in digital payment channels, fraudulent transactions are occurring in new and different ways. This number is increasing rapidly.
In the banking industry, credit card fraud detection using machine learning is not just a trend. It is necessary for players in the industry to put proactive monitoring and fraud prevention mechanisms in place. Machine learning is helping them reduce time-consuming manual reviews, costly chargebacks and fees, and denials of legitimate transactions.

Understanding and defining fraud
Credit card fraud is any dishonest act or behavior whose goal is to obtain information without proper authorization from the account holder for financial gain. Among different ways of committing fraud, skimming is the most common one, which is a way of duplicating information located on the card’s magnetic strip. A few other ways are given below:
●     Manipulation/alteration of genuine cards
●     Creation of counterfeit cards
●     Stealing/loss of credit cards
●     Fraudulent telemarketing

Data dictionary
The data set can be downloaded using this link.
The data set includes credit card transactions made by European cardholders for 2 days in September 2013. Out of the 284,807 transactions in total, 492 were fraudulent. This data set is highly unbalanced, with the positive class (frauds) accounting for 0.172% of the total transactions. The data set has also been modified with principal component analysis (PCA) to maintain confidentiality. Apart from “time” and “amount,” all the other features (V1, V2, V3, up to V28) are the principal components obtained using PCA. The feature “time” contains the seconds elapsed between the first transaction in the data set and the subsequent transactions. The feature “amount” is the transaction amount. The feature “class” represents class labeling, and it takes the value of 1 in cases of fraud and 0 in others.

Project pipeline
The project pipeline can be briefly summarized in the following four steps:
●     Data understanding: Here, you need to load the data and understand the features present in it. This would help you choose the features that you will need for your final model.
●     Exploratory data analytics (EDA): Usually, in this step, you need to perform univariate and bivariate analyses of the data, followed by feature transformations, if necessary. For the current data set, because Gaussian variables are used, you need not perform Z-scaling. However, you can check whether there is any skewness in the data and try to mitigate it, as it might cause problems during the model building phase.
●     Train/Test split: Now, you are familiar with the train/test split that you can perform to check the performance of your models with unseen data. Here, for validation, you can use the k-fold cross-validation method. You need to choose an appropriate k value so that the minority class is correctly represented in the test folds.
●     Model building / hyperparameter tuning: This is the final step where you can try different models and fine-tune their hyperparameters until you get the desired level of performance on the given data set. You should try and check if you get a better model by various sampling techniques.
●     Model evaluation: Here, you need to evaluate the models using appropriate evaluation metrics. Note that since the data is imbalanced, it is more important to identify fraudulent transactions accurately than non-fraudulent ones. Choose an appropriate evaluation metric that reflects this business goal.
